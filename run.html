<!DOCTYPE html>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- https://github.com/karpathy/llama2.c#notable-forks -->
<title>llama2.js</title>
<style>
  body {
    padding: 1em;
  }

  label,
  button {
    margin: 0.5em;
  }

  input {
    width: 5em;
  }

  textarea {
    padding: 1em;
  }
</style>

<body>
  <div id="app">
    <div>
      <textarea v-model="state.prompt" cols="80" rows="1" placeholder="One day"></textarea>
    </div>
    
    <div>
      <select v-model="state.model">
        <option value="stories15m">stories15m</option>
        <option value="stories42m">stories42m</option>
        <option value="stories110m">stories110m</option>
      </select>
      <label>top-p</label><input v-model.number="state.topP" type="number" step="0.1" />
      <label>temperature</label><input v-model.number="state.temperature" type="number" step="0.1" />
      <label>steps</label><input v-model.number="state.steps" type="number" />
      <button @click="generate">run</button>
    </div>
    <textarea id="output" rows="20" cols="80" v-model="state.output"></textarea>
    <p><span>achieved tok/s: </span><span id="toks">{{ state.toks }}</span></p>
  </div>

  <script type="module">
    import { createApp, reactive } from 'https://unpkg.com/vue@3/dist/vue.esm-browser.js'
    import { load_model, load_vocab, generator } from "./llama2.js";

    const app = createApp({
      setup() {
        const state = reactive({
          prompt: "",
          model: "stories15m",
          topP: 1.0,
          temperature: 0.9,
          steps: 100,
          output: "",
          toks: 0
        });

        async function generate() {
          state.output = "";
          state.toks = 0;

          const iterator = await generator({
            temperature: parseFloat(state.temperature),
            prompt: state.prompt,
            topp: parseFloat(state.topP),
            steps: parseInt(state.steps),
          });

          while (true) {
            const { value, done } = await iterator.next();
            if (done) {
              console.log(value);
              break;
            }
            state.toks = value.toks.toFixed(4);
            state.output += value.next;
          }
        }

        async function loadModel() {
          await load_model("./models/stories15m.bin");
          // await load_model("https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin");
          await load_vocab("./tokenizer.bin");
        }

        return {
          state,
          generate,
          loadModel,
        };
      },
      mounted() {
        this.loadModel();
      },
    });

    app.mount("#app");
  </script>
</body>